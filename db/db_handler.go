package db

import (
	"encoding/json"
	"fmt"
	"github.com/astaxie/beego/logs"
	"gopkg.in/goracle.v2"
	_ "gopkg.in/goracle.v2"
	"regexp"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"db_mirror/common"
	. "db_mirror/entity"
	"xorm.io/xorm"
	"xorm.io/xorm/log"
	"xorm.io/xorm/schemas"
)

type HandlerDb struct {
	Engine  *xorm.Engine
	Setting *Setting
}

var handlerDbMap map[int]*HandlerDb

func NewHandlerDb(db_id int) *HandlerDb {

	if val, ok := handlerDbMap[db_id]; ok {
		return val
	} else {
		if handlerDbMap == nil {
			handlerDbMap = make(map[int]*HandlerDb)
		}
		setting, err := Sqlite_NewDb().Sqlite_GetDbSetting(db_id)
		common.ErrorHandler(err, "sqliteè·å–DBé…ç½®é”™è¯¯::%s")
		// è·å–å¼•æ“
		engine, err := xorm.NewEngine("goracle", GetDataSource(*setting))
		common.ErrorHandler(err, "sqliteæ‰“å¼€å‘ç”Ÿé”™è¯¯::%s")
		/* å¼•æ“é…ç½® */
		engine.SetMaxIdleConns(10)
		engine.SetMaxOpenConns(2000)
		//engine.ShowSQL(true)
		// logé…ç½®åˆ°BeeLoggerä¸‹
		engine.SetLogger(log.NewSimpleLogger(logs.GetBeeLogger()))
		engine.Logger().SetLevel(log.LOG_DEBUG)
		// *é…ç½®*
		engine.Logger().ShowSQL(false)

		handlerDbMap[db_id] = &HandlerDb{Engine: engine, Setting: setting} // é»˜è®¤å‘½åç©ºé—´ä¸ç”¨æˆ·åä¸€è‡´
		logs.Info(fmt.Sprintf("%sæ•°æ®åº“Engineåˆå§‹åŒ–æˆåŠŸ", db_id))
		return handlerDbMap[db_id]
	}
}

func TestDb(s Setting) (reErr error) {
	// å¯¹å¤–é”™è¯¯å¤„ç†
	defer common.RecoverHandler(func(err interface{}) {
		reErr = fmt.Errorf("è¿æ¥DBå¤±è´¥:%s", err)
	})

	// è·å–å¼•æ“
	engine, err := xorm.NewEngine("goracle", GetDataSource(s))
	common.ErrorHandler(err)
	// å¼•æ“å…³é—­
	defer engine.Close()

	rows, err := engine.QueryString("select count(1) from dual")
	common.ErrorHandler(err)
	if rows != nil && len(rows) > 0 {
		return nil
	} else {
		// ä¸šåŠ¡err
		return fmt.Errorf("è¿æ¥DBå¤±è´¥")
	}
}

/*
	æ‹¼æ¥è¯·æ±‚é“¾æ¥  ç»“æ„å‚ç…§ "SZHTCL/SZHTCL@114.115.146.150:1521/orcl"
*/
func GetDataSource(s Setting) string {
	return fmt.Sprint(s.Username, "/", s.Password, "@", s.Ip, ":", s.Port, "/", s.ServiceName)
}

func CopyDDL(backupDb Backup_DB) (createTableInfos []string, reErr error) {
	// å¯¹å¤–é”™è¯¯å¤„ç†
	defer common.RecoverHandler(func(err interface{}) {
		reErr = fmt.Errorf("DBè¿›è¡ŒDDLæ“ä½œå¤±è´¥:%s", err)
	})
	goroutineNum := 5
	if runtime.GOOS != "windows" {
		goroutineNum = 1
	}
	// è·å–DbIdFromå’ŒDbIdTo
	b, b_err := Sqlite_NewDb().Sqlite_GetDbbackupSetting(backupDb.BackupId)
	common.ErrorHandler(b_err)
	backupDb = *b

	handlerDb_from := NewHandlerDb(backupDb.DbIdFrom)
	engine_from := handlerDb_from.Engine
	setting_from := handlerDb_from.Setting

	handlerDb_to := NewHandlerDb(backupDb.DbIdTo)
	engine_to := handlerDb_to.Engine
	setting_to := handlerDb_to.Setting

	tables, err := engine_from.DBMetas()
	if err != nil {
		common.ErrorHandler(err)
	}

	// è€ƒè™‘:é‡å¤å»ºè¡¨çš„æƒ…å†µï¼Œè®°å½•æ¯ä¸€æ¬¡DDLï¼Œå…¼å®¹è¿½åŠ è¡¨ä¹‹åï¼Œåœ¨å¤‡ä»½åº“è¿½åŠ è¯¥è¡¨çš„æƒ…å†µ
	createTableInfos = []string{}

	type ddl_chan struct {
		table_info string
		ddl        string
		err        error
	}
	// ç”¨äºå°†æ¥æºç–¯ç‹‚è¾“å‡º
	channel_tables := make(chan *schemas.Table, goroutineNum)
	// ç”¨äºæ¶ˆè´¹è€…å‘é€å¤„ç†åçš„æ•°æ®
	channel_ddl := make(chan *ddl_chan, goroutineNum)
	wg := sync.WaitGroup{}
	wg.Add(len(tables))
	// ç–¯ç‹‚è¾“å‡º
	go func() {
		for _, t := range tables {
			channel_tables <- t
		}
		// è¾“å‡ºå®Œæˆï¼Œclose channel
		close(channel_tables)
	}()

	go func() {
		wg.Wait()
		// æ¶ˆè´¹è€…å°†å¤„ç†è¿‡çš„æ•°æ®è¿›è¡Œå‘é€ï¼Œç´¯è®¡å‘é€æ¬¡æ•°ï¼Œç„¶åå…³é—­éš§é“
		close(channel_ddl)
	}()

	for i := 0; i < goroutineNum; i++ {
		//é™æµXä¸ªåç¨‹ï¼Œå¦‚æœå‘ç”Ÿéä¸šåŠ¡é”™è¯¯ï¼Œå°±panic
		go func(channel_tables_in chan *schemas.Table) {
			// å¯¹å¤–é”™è¯¯å¤„ç†
			defer common.RecoverHandler(func(err interface{}) {
				channel_ddl <- &ddl_chan{
					table_info: "",
					err:        fmt.Errorf("å¤‡ä»½åº“åˆ›å»ºè¡¨å‘ç”Ÿé”™è¯¯::%s", err),
				}
			})

			for t := range channel_tables_in {

				var valuesMap = make(map[string]string)
				_, err := engine_from.SQL(fmt.Sprintf("select dbms_metadata.get_ddl('TABLE','%s') as ddl from dual", t.Name)).Get(&valuesMap)
				if err != nil {
					common.ErrorHandler(err)
				}
				ddl := valuesMap["DDL"]
				// CREATE TABLE "SZHTCL"."CGAREABT"  ä¿®æ”¹å‘½åç©ºé—´  è¿½åŠ äº†ç”¨æˆ·åå˜å¤§å†™
				ddl = strings.Replace(ddl, fmt.Sprintf(`CREATE TABLE "%s".`, strings.ToUpper(setting_from.Username)),
					fmt.Sprintf(`CREATE TABLE "%s".`, strings.ToUpper(setting_to.Username)), -1)
				// TABLESPACE "SZHTCL"   ä¿®æ”¹å‘½åç©ºé—´  è¿½åŠ äº†ç”¨æˆ·åå˜å¤§å†™
				ddl = strings.Replace(ddl, fmt.Sprintf(`TABLESPACE "%s"`, strings.ToUpper(setting_from.Username)),
					fmt.Sprintf(`TABLESPACE "%s"`, strings.ToUpper(setting_to.Username)), -1)

				var createTableInfo string

				_, err_ddl := engine_to.Exec(ddl)
				if err_ddl != nil {
					if strings.Index(err_ddl.Error(), "ORA-00955") > 0 { //ä¸šåŠ¡é”™è¯¯ï¼Œä¸panic
						createTableInfo = fmt.Sprintf("Warning::å¤‡ä»½åº“åˆ›å»ºè¡¨å¤±è´¥ï¼Œå·²ç»å­˜åœ¨è¡¨[%s]", t.Name)
					} else {
						common.ErrorHandler(err_ddl, t.Name, ddl)
					}
				} else {
					createTableInfo = fmt.Sprintf("Info::å¤‡ä»½åº“åˆ›å»ºè¡¨æˆåŠŸï¼Œåˆ›å»ºè¡¨[%s]", t.Name)
					// æ‰§è¡Œå»ºè¡¨ddlæ–‡æˆåŠŸï¼Œè®°å½•sqlite

					// è®°å…¥é»˜è®¤æ›´æ–°ç­–ç•¥
					strategyMap := make(map[string]bool)
					strategyMap["isCopy"] = true
					strategyMap["hasPkForIncrement"] = true
					strategyMap["cleanCopy"] = false
					strategyMap["smartCopy"] = true
					strategyMapJsonByte, _ := json.Marshal(strategyMap)
					saveTblErr := Sqlite_NewDb().Sqlite_SaveBackupDbTableSetting(
						Backup_Table{
							BackupId:  backupDb.BackupId,
							TableName: t.Name,
							DDL:       ddl,
							Strategy:  string(strategyMapJsonByte),
							Key:       getKeyFromDdl(ddl),
						})
					common.ErrorHandler(saveTblErr)
				}
				logs.Info(createTableInfo)
				// æ­£å¸¸çš„åœºåˆ
				channel_ddl <- &ddl_chan{
					table_info: createTableInfo,
					ddl:        ddl,
					err:        nil,
				}
				wg.Done()
			}
		}(channel_tables)
	}

	for c := range channel_ddl {
		if c.err != nil {
			common.ErrorHandler(c.err)
		} else {
			createTableInfos = append(createTableInfos, c.table_info)
		}
	}

	return createTableInfos, nil
}

func GoCopy(backupDb Backup_DB, isFirst ...bool) (errlogs []string, reErr error) {

	firstGo := false
	if isFirst != nil && len(isFirst) > 0 && isFirst[0] == true {
		logs.Info(fmt.Sprintf("%s,%sé¦–æ¬¡å¤‡ä»½æ‰§è¡Œ::firstGo=true", backupDb.BackupId, backupDb.Desc))
		firstGo = true
	}

	// å¯¹å¤–é”™è¯¯å¤„ç†
	defer common.RecoverHandler(func(err interface{}) {
		reErr = fmt.Errorf("DBè¿›è¡Œå¤‡ä»½æ“ä½œå¤±è´¥:%s", err)
	})

	handlerDb_from := NewHandlerDb(backupDb.DbIdFrom)
	engine_from := handlerDb_from.Engine

	handlerDb_to := NewHandlerDb(backupDb.DbIdTo)
	engine_to := handlerDb_to.Engine

	// é”™è¯¯è®°å½•ï¼Œä¸»è¦ç”¨äºè¿”å›å‘ç”Ÿé”™è¯¯çš„ä¿¡æ¯ç»™è°ƒç”¨è€…
	errLogs := []string{}
	errLogFunc := func(err_func error, err_sql string) {
		logs.Error(err_func, err_sql)
		errLogs = append(errLogs, err_func.Error(), err_sql)
	}

	bakTblsSetting, err := Sqlite_NewDb().Sqlite_GetDbTableSetting(backupDb.BackupId)
	common.ErrorHandler(err)

	bakTbl_chan := make(chan *Backup_Table, 10)
	wg := sync.WaitGroup{}

	wg.Add(len(bakTblsSetting))
	go func() {
		for _, b := range bakTblsSetting {
			bakTbl_chan <- b
		}
		close(bakTbl_chan)
	}()
	goroutineNum := 10
	if runtime.GOOS != "windows" {
		goroutineNum = 1
	}

	/*
		è·å–dbæ‰§è¡Œlogï¼Œè·å–è¢«æ›´æ–°çš„è¡¨ä¿¡æ¯ï¼Œç”¨äºåˆ¤æ–­æŸæ—¶é—´åï¼Œè¯¥è¡¨æ˜¯å¦è¢«æ›´æ–°è¿‡
		ä»è€Œåªèƒ½åˆ¤æ–­æ˜¯å¦é‡æ–°å¤‡ä»½è¯¥è¡¨
	*/
	updateTables, errSmartLog := GetDbExecuteLog(backupDb)
	if errSmartLog != nil {
		common.ErrorHandler(errSmartLog)
	}

	for i := 0; i < goroutineNum; i++ {
		go func() {
			for b := range bakTbl_chan {
				/*
					strategy è¡¨å¤‡ä»½ç­–ç•¥ï¼š
					1ï¼Œæ˜¯å¦éœ€è¦å¤‡ä»½
					2ï¼Œæ ¹æ®ä¸»é”®å¢é‡å¤‡ä»½ï¼ˆupdate or insertï¼‰
					3ï¼Œå®Œå…¨æ¸…ç©ºå¤‡ä»½è¡¨ï¼Œä»ä¸»è¡¨å…¨é‡copy
					4ï¼Œè·å–DBæ—¥å¿—ï¼Œåªèƒ½åˆ¤æ–­è¯¥è¡¨æ˜¯å¦æœ‰è¿‡æ›´æ–°æ“ä½œï¼Œç„¶åè¿›è¡Œ2æˆ–3çš„å¤‡ä»½
					{
						"isCopy":true,
						"hasPkForIncrement":true,
						"cleanCopy":false,
						"smartCopy":true
					}
				*/
				strategyMap := make(map[string]bool)
				if firstGo {
					if b.Strategy == "" {
						// ç¬¬ä¸€æ¬¡æ‰§è¡Œ
						// å…¨ç›˜å¤‡ä»½
						strategyMap["isCopy"] = true
						strategyMap["hasPkForIncrement"] = false
						strategyMap["cleanCopy"] = true
						strategyMap["smartCopy"] = false
					} else {
						unmarshalJsonErr := json.Unmarshal([]byte(b.Strategy), &strategyMap)
						if unmarshalJsonErr != nil {
							errLogFunc(fmt.Errorf("è§£æ[%s]è¡¨å¤‡ä»½ç­–ç•¥æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, unmarshalJsonErr), "")
							wg.Done()
							continue
						}
					}

				} else {
					// éç¬¬ä¸€æ¬¡æ‰§è¡Œ
					if b.Strategy == "" {
						// è€ƒè™‘è¡¨ç­–ç•¥ä¸ºç©ºçš„æƒ…å†µï¼Œåˆå§‹åŒ– default
						strategyMap["isCopy"] = true
						strategyMap["hasPkForIncrement"] = true
						strategyMap["cleanCopy"] = false
						strategyMap["smartCopy"] = true
					} else {
						unmarshalJsonErr := json.Unmarshal([]byte(b.Strategy), &strategyMap)
						if unmarshalJsonErr != nil {
							errLogFunc(fmt.Errorf("è§£æ[%s]è¡¨å¤‡ä»½ç­–ç•¥æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, unmarshalJsonErr), "")
							wg.Done()
							continue
						}
					}
				}

				//1ï¼Œå¦‚æœä¸éœ€è¦å¤‡ä»½ï¼Œå°±è·³è¿‡ï¼Œå‡å»wait
				if !strategyMap["isCopy"] {
					wg.Done()
					continue
				}
				//2,æ˜¯å¦æ™ºèƒ½åˆ¤æ–­æ›´æ–°
				// -1:æ— å…³æ™ºèƒ½åˆ¤æ–­ï¼Œåç»­æ­£å¸¸æ‰§è¡Œ
				// 0:æ™ºèƒ½åˆ¤æ–­ï¼Œæ²¡æœ‰å‘ç”Ÿå˜åŒ–
				// 1:æ™ºèƒ½åˆ¤æ–­ï¼Œå‘ç”Ÿå˜åŒ–
				smartCopyCheck := -1
				if strategyMap["smartCopy"] {
					// éœ€è¦æ™ºèƒ½åˆ¤æ–­
					smartCopyCheck = 0
					if backupDb.SmartLogTime == "" {
						// æ²¡æœ‰æ›´æ–°æ—¶é—´ï¼Œè§†ä¸ºå‘ç”Ÿå˜åŒ–
						smartCopyCheck = 1
						logs.Info(fmt.Sprintf("è¡¨[%s]é€šè¿‡æ™ºèƒ½åˆ¤æ–­ï¼Œå¤‡ä»½æ—¶é—´è®°å½•ä¸ºç©ºï¼Œè¿›è¡Œå¤‡ä»½", b.TableName))
					} else {
						for _, u := range updateTables {
							if strings.ToUpper(u) == strings.ToUpper(b.TableName) {
								// å‘ç”Ÿå˜åŒ–
								smartCopyCheck = 1
								logs.Info(fmt.Sprintf("è¡¨[%s]é€šè¿‡æ™ºèƒ½åˆ¤æ–­ï¼Œå‘ç”Ÿå˜åŒ–ï¼Œè¿›è¡Œå¤‡ä»½", b.TableName))
								break
							}
						}
					}
					// æ²¡å‘ç”Ÿå˜åŒ–
					if smartCopyCheck == 0 {
						logs.Info(fmt.Sprintf("è¡¨[%s]é€šè¿‡æ™ºèƒ½åˆ¤æ–­ï¼Œæ²¡æœ‰å‘ç”Ÿå˜åŒ–", b.TableName))
						wg.Done()
						continue
					}
				}

				// è·å–ç›®æ ‡è¡¨æ‰€æœ‰æ•°æ®
				sql1 := "select * from " + b.TableName
				// ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ æ•°æ®ï¼Œé›†ä¸­å¤„ç†
				results_map_interface, err := engine_from.SQL(sql1).QueryInterface()
				if err != nil {
					errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, err), sql1)
					goto wgFlg
				}
				/*
					FIXME âŒğŸš«ğŸš«â›”ï¸â›”  ç‰¹åˆ«æ³¨æ„~ï¼ä»¥ä¸‹ä»£ç ä¸­æ‰€æœ‰æ“ä½œéƒ½æ˜¯é’ˆå¯¹å¤‡ä»½æ•°æ®åº“è¡¨çš„ï¼Œæ³¨æ„engine_to  â›”ï¸â›”ğŸš«ğŸš«ï¸âŒ
				*/
				// æ›´æ–°ç­–ç•¥ä¸ºä¸»é”®æ›´æ–°ï¼Œä¸”è¯¥è¡¨æ‹¥æœ‰ä¸»keyçš„æƒ…å†µä¸‹
				if strategyMap["smartCopy"] && b.Key != "" {
					for _, up := range results_map_interface {
						k := strings.Split(b.Key, ",")
						where_sql := ""
						for i, s := range k {
							switch up[s].(type) {
							case string:
								where_sql = where_sql + s + " = '" + up[s].(string) + "'"
							case int:
								where_sql = where_sql + s + " = " + strconv.Itoa(up[s].(int)) + ""
							case int64:
								where_sql = where_sql + s + " = " + strconv.FormatInt(up[s].(int64), 10) + ""
							case goracle.Number:
								where_sql = where_sql + s + " = " + up[s].(goracle.Number).String() + ""
							default:
								errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::key[%s]%s", b.TableName, s, "æ— æ³•è½¬æ¢ç±»å‹"), "")
								goto wgFlg
							}
							if i != len(k)-1 {
								where_sql = where_sql + " and "
							}
						}
						/*xorm çš„ update ID æ–¹å¼å®åœ¨ä¸ä¼šç”¨äº†ï¼Œè°ä¼šå¸®æˆ‘æŠŠè¿™å—æ”¹äº†å§ FIXME*/
						updateNum, err := engine_to.Table(b.TableName).Where(where_sql).Update(up)
						if err != nil {
							sql2 := "tablename::" + b.TableName + " where_sql::" + where_sql + " Update::" + fmt.Sprintf("%+v", up)
							errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, err), sql2)
							goto wgFlg
						}
						// update or insert
						if updateNum == 0 {
							_, err := engine_to.Table(b.TableName).Insert(up)
							if err != nil {
								sql3 := "tablename::" + b.TableName + " Insert::" + fmt.Sprintf("%+v", up)
								errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, err), sql3)
								goto wgFlg
							}
						}
						//logs.Info("è¡¨ ["+b.TableName+"] ", "é€šè¿‡pk::", where_sql, " å¤‡ä»½æˆåŠŸ")
					}
				} else {
					// è¯¥è¡¨æ²¡æœ‰ä¸»keyçš„æƒ…å†µä¸‹
					// é¢å¤–å¤„ç†ï¼šåˆ¤æ–­åŸè¡¨æ˜¯å¦æœ‰æ•°æ®(æ•°æ®é‡å°‘äºå¤‡ä»½åº“)ï¼Œå¦‚æœåŸè¡¨ä¸ºç©ºï¼Œä¸è¿›è¡Œæ¸…ç©ºå¤‡ä»½è¡¨çš„æ“ä½œ
					if !countEqual(engine_from, engine_to, b.TableName) {
						errLogFunc(fmt.Errorf("[%s]è¡¨åŸåº“ä¸­æ•°æ®å°‘äºå¤‡ä»½åº“ä¸­æ•°æ®ï¼Œæ‹’ç»æ¸…ç©ºå¤‡ä»½åº“åå¤‡ä»½ï¼Œè¯·æ£€æŸ¥::", b.TableName), "")
						goto wgFlg
					}
					_, err_truncate := engine_to.Exec("TRUNCATE TABLE " + b.TableName)
					if err_truncate != nil {
						sql5 := "tablename::" + b.TableName + " TRUNCATE "
						errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, err), sql5)
						goto wgFlg
					}
					_, err := engine_to.Table(b.TableName).Insert(results_map_interface)
					if err != nil {
						sql4 := "tablename::" + b.TableName + " Insert::" + fmt.Sprintf("%+v", results_map_interface)
						errLogFunc(fmt.Errorf("å¤‡ä»½[%s]è¡¨æ—¶å‘ç”Ÿé”™è¯¯::%s", b.TableName, err), sql4)
						goto wgFlg
					}
					logs.Info("è¡¨ ["+b.TableName+"] ", "å…¨æ’å…¥æˆåŠŸ")
				}
			wgFlg:
				wg.Done()
			}
		}()
	}

	wg.Wait()

	return errLogs, nil
}

func countEqual(engine_from *xorm.Engine, engine_to *xorm.Engine, tableName string) bool {
	mapStringInterfaceArray1, err := engine_from.SQL("select count(1) as num from " + tableName).QueryString()
	if err != nil {
		logs.Error(fmt.Errorf("æŸ¥è¯¢[%s]è¡¨æ•°æ®æ€»é‡å‘ç”Ÿé”™è¯¯(from)::", tableName), "")
		return false
	}
	mapStringInterface1 := mapStringInterfaceArray1[0]
	from_num := mapStringInterface1["NUM"]
	from, _ := strconv.ParseInt(from_num, 10, 64)
	mapStringInterfaceArray2, err := engine_to.SQL("select count(1) as num from " + tableName).QueryString()
	if err != nil {
		logs.Error(fmt.Errorf("æŸ¥è¯¢[%s]è¡¨æ•°æ®æ€»é‡å‘ç”Ÿé”™è¯¯(to)::", tableName), "")
		return false
	}
	mapStringInterface2 := mapStringInterfaceArray2[0]
	to_num := mapStringInterface2["NUM"]
	to, _ := strconv.ParseInt(to_num, 10, 64)
	return from >= to
}

func getKeyFromDdl(ddl string) string {
	// ä¾‹å­ PRIMARY KEY ("ID", "TESTCOL")
	reg, err := regexp.Compile("PRIMARY KEY \\((.*)\\)")
	if err != nil {
		common.ErrorHandler(err)
	}
	ss := reg.FindStringSubmatch(ddl)
	if len(ss) == 2 {
		return strings.Replace(strings.Replace(ss[1], "\"", "", -1),
			" ", "", -1)
	} else {
		return ""
	}
}

func GetDbExecuteLog(backupDb Backup_DB) (updatedTables []string, reErr error) {
	// å¯¹å¤–é”™è¯¯å¤„ç†
	defer common.RecoverHandler(func(err interface{}) {
		reErr = fmt.Errorf("è·å–DBæ“ä½œæ—¥å¿—å¤±è´¥:%s", err)
	})

	bk, err := Sqlite_NewDb().Sqlite_GetDbbackupSetting(backupDb.BackupId)
	common.ErrorHandler(err)
	// æ‹¿å‡ºä¸Šæ¬¡çš„æ—¶é—´ï¼Œé©¬ä¸ŠæŠŠè¿™æ¬¡æ—¶é—´å­˜å…¥
	// Backup_DBæ›´æ–°SmartLogTime
	// smartLogTimeè®°å½•
	Sqlite_NewDb().Sqlite_UpdateSmartLogTime(backupDb.BackupId)

	updatedTables = make([]string, 0)

	// æ²¡æœ‰æ›´æ–°æ—¶é—´ï¼Œè§†ä¸ºå‘ç”Ÿå˜åŒ–
	if bk.SmartLogTime == "" {
		return updatedTables, nil
	}

	// è·å– SCHEMA_NAME
	db_from_setting, setting_err := Sqlite_NewDb().Sqlite_GetDbSetting(backupDb.DbIdFrom)
	if setting_err != nil {
		common.ErrorHandler(setting_err)
	}

	handlerDb_from := NewHandlerDb(backupDb.DbIdFrom)
	engine_from := handlerDb_from.Engine
	dbELogArray := make([]DbExecuteLog, 0)
	dbELogSql := fmt.Sprintf(`
SELECT t.SQL_FULLTEXT as sql_full_text,
       t.FIRST_LOAD_TIME as first_load_time
FROM v$sqlarea t
WHERE to_date(t.FIRST_LOAD_TIME, 'yyyy-MM-dd hh24:mi:ss') > to_date('%s', 'yyyy-MM-dd hh24:mi:ss')
  AND t.PARSING_SCHEMA_NAME = '%s'
  AND (
        (INSTR(LOWER(t.SQL_FULLTEXT), 'update') > 0
            AND INSTR(LOWER(t.SQL_FULLTEXT), 'update') < 10)
        OR
        (INSTR(LOWER(t.SQL_FULLTEXT), 'insert') > 0
            AND INSTR(LOWER(t.SQL_FULLTEXT), 'insert') < 10)
    )
ORDER BY t.FIRST_LOAD_TIME DESC
`, bk.SmartLogTime, db_from_setting.Username)

	errFind := engine_from.SQL(dbELogSql).Find(&dbELogArray)
	if errFind != nil {
		common.ErrorHandler(errFind)
	}

	for _, dbElog := range dbELogArray {
		reg, _ := regexp.Compile(`(?i)update (\w+) |insert into (\w+) |update \w+\.(\w+) |insert into \w+\.(\w+) `)
		ss := reg.FindStringSubmatch(strings.Replace(dbElog.SqlFullText, "\"", "", -1))
		//logs.Info("smartLogåŒ¹é…çš„è¡¨::", ss)
		// å¤„ç†é‡å¤
		if len(ss) > 0 {
			for i := 1; i < len(ss); i++ {
				if ss[i] != "" && !isDuplicate(updatedTables, ss[i]) {
					updatedTables = append(updatedTables, ss[i])
				}
			}
		}
	}
	logs.Info("updatedTables::", updatedTables)
	return
}

func isDuplicate(a []string, x string) bool {
	for i := 0; i < len(a); i++ {
		if a[i] == x {
			return true // é‡å¤
		}
	}
	return false
}
